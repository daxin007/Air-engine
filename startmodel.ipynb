{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalution function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def score(y_true, y_pred):\n",
    "    s = 0\n",
    "    for r_true, r_pred in zip(y_true, y_pred):\n",
    "        d = r_pred - r_true\n",
    "#         print(d)\n",
    "        if d < 0 :\n",
    "            s+=(math.exp(-d/13)-1)\n",
    "        else:\n",
    "            s+=(math.exp(d/10)-1)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20631, 26)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "f = open('train_FD001.txt')\n",
    "lines = f.readlines()\n",
    "res = []\n",
    "for i in lines:\n",
    "    res.append(i.split(' ')[:-2])\n",
    "res_array = np.array(res)\n",
    "res_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_tmp = ['unit number','time','operational setting 1','operational setting 2','operational setting 3',\\\n",
    "               'sensor measurement  1','sensor measurement  2','sensor measurement  3','sensor measurement  4',\\\n",
    "               'sensor measurement  5','sensor measurement  6','sensor measurement  7','sensor measurement  8',\\\n",
    "               'sensor measurement  9','sensor measurement  10','sensor measurement  11','sensor measurement  12',\\\n",
    "               'sensor measurement  13','sensor measurement  14','sensor measurement  15','sensor measurement  16',\\\n",
    "               'sensor measurement  17','sensor measurement  18','sensor measurement  19','sensor measurement  20',\\\n",
    "               'sensor measurement  21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit number</th>\n",
       "      <th>time</th>\n",
       "      <th>operational setting 1</th>\n",
       "      <th>operational setting 2</th>\n",
       "      <th>operational setting 3</th>\n",
       "      <th>sensor measurement  1</th>\n",
       "      <th>sensor measurement  2</th>\n",
       "      <th>sensor measurement  3</th>\n",
       "      <th>sensor measurement  4</th>\n",
       "      <th>sensor measurement  5</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor measurement  12</th>\n",
       "      <th>sensor measurement  13</th>\n",
       "      <th>sensor measurement  14</th>\n",
       "      <th>sensor measurement  15</th>\n",
       "      <th>sensor measurement  16</th>\n",
       "      <th>sensor measurement  17</th>\n",
       "      <th>sensor measurement  18</th>\n",
       "      <th>sensor measurement  19</th>\n",
       "      <th>sensor measurement  20</th>\n",
       "      <th>sensor measurement  21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.66</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.00</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.28</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.42</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.00</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.86</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.00</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.19</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.00</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  unit number time operational setting 1 operational setting 2  \\\n",
       "0           1    1               -0.0007               -0.0004   \n",
       "1           1    2                0.0019               -0.0003   \n",
       "2           1    3               -0.0043                0.0003   \n",
       "3           1    4                0.0007                0.0000   \n",
       "4           1    5               -0.0019               -0.0002   \n",
       "\n",
       "  operational setting 3 sensor measurement  1 sensor measurement  2  \\\n",
       "0                 100.0                518.67                641.82   \n",
       "1                 100.0                518.67                642.15   \n",
       "2                 100.0                518.67                642.35   \n",
       "3                 100.0                518.67                642.35   \n",
       "4                 100.0                518.67                642.37   \n",
       "\n",
       "  sensor measurement  3 sensor measurement  4 sensor measurement  5  \\\n",
       "0               1589.70               1400.60                 14.62   \n",
       "1               1591.82               1403.14                 14.62   \n",
       "2               1587.99               1404.20                 14.62   \n",
       "3               1582.79               1401.87                 14.62   \n",
       "4               1582.85               1406.22                 14.62   \n",
       "\n",
       "           ...           sensor measurement  12 sensor measurement  13  \\\n",
       "0          ...                           521.66                2388.02   \n",
       "1          ...                           522.28                2388.07   \n",
       "2          ...                           522.42                2388.03   \n",
       "3          ...                           522.86                2388.08   \n",
       "4          ...                           522.19                2388.04   \n",
       "\n",
       "  sensor measurement  14 sensor measurement  15 sensor measurement  16  \\\n",
       "0                8138.62                 8.4195                   0.03   \n",
       "1                8131.49                 8.4318                   0.03   \n",
       "2                8133.23                 8.4178                   0.03   \n",
       "3                8133.83                 8.3682                   0.03   \n",
       "4                8133.80                 8.4294                   0.03   \n",
       "\n",
       "  sensor measurement  17 sensor measurement  18 sensor measurement  19  \\\n",
       "0                    392                   2388                 100.00   \n",
       "1                    392                   2388                 100.00   \n",
       "2                    390                   2388                 100.00   \n",
       "3                    392                   2388                 100.00   \n",
       "4                    393                   2388                 100.00   \n",
       "\n",
       "  sensor measurement  20 sensor measurement  21  \n",
       "0                  39.06                23.4190  \n",
       "1                  39.00                23.4236  \n",
       "2                  38.95                23.3442  \n",
       "3                  38.88                23.3739  \n",
       "4                  38.90                23.4044  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(res_array,columns=columns_tmp)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit number</th>\n",
       "      <th>time</th>\n",
       "      <th>operational setting 1</th>\n",
       "      <th>operational setting 2</th>\n",
       "      <th>operational setting 3</th>\n",
       "      <th>sensor measurement  1</th>\n",
       "      <th>sensor measurement  2</th>\n",
       "      <th>sensor measurement  3</th>\n",
       "      <th>sensor measurement  4</th>\n",
       "      <th>sensor measurement  5</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor measurement  12</th>\n",
       "      <th>sensor measurement  13</th>\n",
       "      <th>sensor measurement  14</th>\n",
       "      <th>sensor measurement  15</th>\n",
       "      <th>sensor measurement  16</th>\n",
       "      <th>sensor measurement  17</th>\n",
       "      <th>sensor measurement  18</th>\n",
       "      <th>sensor measurement  19</th>\n",
       "      <th>sensor measurement  20</th>\n",
       "      <th>sensor measurement  21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.66</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.28</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.42</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.86</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.19</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit number  time  operational setting 1  operational setting 2  \\\n",
       "0          1.0   1.0                -0.0007                -0.0004   \n",
       "1          1.0   2.0                 0.0019                -0.0003   \n",
       "2          1.0   3.0                -0.0043                 0.0003   \n",
       "3          1.0   4.0                 0.0007                 0.0000   \n",
       "4          1.0   5.0                -0.0019                -0.0002   \n",
       "\n",
       "   operational setting 3  sensor measurement  1  sensor measurement  2  \\\n",
       "0                  100.0                 518.67                 641.82   \n",
       "1                  100.0                 518.67                 642.15   \n",
       "2                  100.0                 518.67                 642.35   \n",
       "3                  100.0                 518.67                 642.35   \n",
       "4                  100.0                 518.67                 642.37   \n",
       "\n",
       "   sensor measurement  3  sensor measurement  4  sensor measurement  5  \\\n",
       "0                1589.70                1400.60                  14.62   \n",
       "1                1591.82                1403.14                  14.62   \n",
       "2                1587.99                1404.20                  14.62   \n",
       "3                1582.79                1401.87                  14.62   \n",
       "4                1582.85                1406.22                  14.62   \n",
       "\n",
       "            ...            sensor measurement  12  sensor measurement  13  \\\n",
       "0           ...                            521.66                 2388.02   \n",
       "1           ...                            522.28                 2388.07   \n",
       "2           ...                            522.42                 2388.03   \n",
       "3           ...                            522.86                 2388.08   \n",
       "4           ...                            522.19                 2388.04   \n",
       "\n",
       "   sensor measurement  14  sensor measurement  15  sensor measurement  16  \\\n",
       "0                 8138.62                  8.4195                    0.03   \n",
       "1                 8131.49                  8.4318                    0.03   \n",
       "2                 8133.23                  8.4178                    0.03   \n",
       "3                 8133.83                  8.3682                    0.03   \n",
       "4                 8133.80                  8.4294                    0.03   \n",
       "\n",
       "   sensor measurement  17  sensor measurement  18  sensor measurement  19  \\\n",
       "0                   392.0                  2388.0                   100.0   \n",
       "1                   392.0                  2388.0                   100.0   \n",
       "2                   390.0                  2388.0                   100.0   \n",
       "3                   392.0                  2388.0                   100.0   \n",
       "4                   393.0                  2388.0                   100.0   \n",
       "\n",
       "   sensor measurement  20  sensor measurement  21  \n",
       "0                   39.06                 23.4190  \n",
       "1                   39.00                 23.4236  \n",
       "2                   38.95                 23.3442  \n",
       "3                   38.88                 23.3739  \n",
       "4                   38.90                 23.4044  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.astype('float')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = []\n",
    "for i in range(1,101):\n",
    "    test = df[df[\"unit number\"]==i]\n",
    "    test = test.reset_index()\n",
    "    test = test.drop(columns = 'index')\n",
    "#     test = test.ix[:, (test != test.ix[0]).any()]\n",
    "#     test = test.set_index('time')\n",
    "    units.append(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load test data and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('test_FD001.txt')\n",
    "lines = f.readlines()\n",
    "res = []\n",
    "for i in lines:\n",
    "    res.append(i.split(' ')[:-2])\n",
    "res_array = np.array(res)\n",
    "res_array.shape\n",
    "df = pd.DataFrame(res_array,columns=columns_tmp)\n",
    "df.head()\n",
    "df = df.astype('float')\n",
    "df.head()\n",
    "test_units = []\n",
    "for i in range(1,101):\n",
    "    test = df[df[\"unit number\"]==i]\n",
    "    test = test.reset_index()\n",
    "    test = test.drop(columns = 'index')\n",
    "#     test = test.ix[:, (test != test.ix[0]).any()]\n",
    "#     test = test.set_index('time')\n",
    "    test_units.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "f = open('RUL_FD001.txt')\n",
    "lines = f.readlines()\n",
    "for i in lines:\n",
    "    labels.append(float(i))\n",
    "# labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Activation, Dropout, LSTM, Input, GlobalMaxPooling1D\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "import keras.backend as K\n",
    "from keras.layers.core import Flatten\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import math\n",
    "from keras.models import Model\n",
    "from keras.layers import Activation, Concatenate, concatenate, Dense, Dropout, Embedding, Input, TimeDistributed,merge,Reshape\n",
    "from keras.layers import GRU,LSTM, CuDNNLSTM, LeakyReLU, Masking, Lambda, Dot, BatchNormalization, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, Flatten\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TerminateOnNaN, ModelCheckpoint\n",
    "from keras_contrib.layers import CRF\n",
    "from keras_contrib.utils import save_load_utils\n",
    "from kutilities.layers import AttentionWithContext\n",
    "from keras.optimizers import Adam, SGD\n",
    "import keras.backend as K\n",
    "from keras.layers import Dense, Activation, Multiply, Add, Lambda\n",
    "import keras.initializers\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM, Input\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((278, 10, 24), (278,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler_minmax = preprocessing.MinMaxScaler()\n",
    "data = units[1]\n",
    "infer_seq_length = 9\n",
    "y = data.time.values[infer_seq_length:]\n",
    "y = max(y) - y\n",
    "y = y/200\n",
    "scale = max(data.time.values[infer_seq_length:])\n",
    "new_data = scaler_minmax.fit_transform(data)\n",
    "# new_data = data.values\n",
    "# new_data = new_data.values\n",
    "# new_data = scaler_minmax.fit_transform(data)\n",
    "\n",
    "d = []\n",
    "for i in range(new_data.shape[0]-infer_seq_length):\n",
    "    d.append(new_data[i:i+infer_seq_length+1].tolist())\n",
    "d = np.array(d)\n",
    "# X = d[:,:,2:]\n",
    "X = d[:,:,2:]\n",
    "# y = d[:,infer_seq_length,1]\n",
    "# y = max(y) - y\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/gjx/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10, 24)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10, 64)            1600      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                32050     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 33,701\n",
      "Trainable params: 33,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model1 FC\n",
    "inputs = Input(shape=(10,24))\n",
    "x = Dense(64, kernel_initializer = keras.initializers.Orthogonal(gain=1.0, seed=None))(inputs)\n",
    "x = Flatten()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(50)(x)\n",
    "x = Activation('relu')(x)\n",
    "predictions = Dense(1, activation='linear')(x)\n",
    "predictions = Activation('relu')(predictions) \n",
    "# predictions = GlobalMaxPooling1D()\n",
    "simple_model = Model(inputs=inputs, outputs=predictions)\n",
    "# sgd = optimizers.SGD(lr=0.01)\n",
    "simple_model.compile(optimizer=\"adam\",loss = 'mse')\n",
    "simple_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model in one unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/gjx/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 222 samples, validate on 56 samples\n",
      "Epoch 1/500\n",
      "222/222 [==============================] - 0s 937us/step - loss: 0.2945 - val_loss: 0.4654\n",
      "Epoch 2/500\n",
      "222/222 [==============================] - 0s 55us/step - loss: 0.0658 - val_loss: 0.0062\n",
      "Epoch 3/500\n",
      "222/222 [==============================] - 0s 51us/step - loss: 0.0399 - val_loss: 0.0092\n",
      "Epoch 4/500\n",
      "222/222 [==============================] - 0s 62us/step - loss: 0.0194 - val_loss: 0.0199\n",
      "Epoch 5/500\n",
      "222/222 [==============================] - 0s 85us/step - loss: 0.0115 - val_loss: 0.0189\n",
      "Epoch 6/500\n",
      "222/222 [==============================] - 0s 68us/step - loss: 0.0112 - val_loss: 0.0217\n",
      "Epoch 7/500\n",
      "222/222 [==============================] - 0s 62us/step - loss: 0.0079 - val_loss: 0.0103\n",
      "Epoch 8/500\n",
      "222/222 [==============================] - 0s 81us/step - loss: 0.0069 - val_loss: 0.0025\n",
      "Epoch 9/500\n",
      "222/222 [==============================] - 0s 53us/step - loss: 0.0062 - val_loss: 0.0043\n",
      "Epoch 10/500\n",
      "222/222 [==============================] - 0s 70us/step - loss: 0.0057 - val_loss: 0.0013\n",
      "Epoch 11/500\n",
      "222/222 [==============================] - 0s 68us/step - loss: 0.0053 - val_loss: 0.0016\n",
      "Epoch 12/500\n",
      "222/222 [==============================] - 0s 60us/step - loss: 0.0047 - val_loss: 0.0019\n",
      "Epoch 13/500\n",
      "222/222 [==============================] - 0s 68us/step - loss: 0.0044 - val_loss: 0.0018\n",
      "Epoch 14/500\n",
      "222/222 [==============================] - 0s 58us/step - loss: 0.0044 - val_loss: 0.0065\n",
      "Epoch 15/500\n",
      "222/222 [==============================] - 0s 91us/step - loss: 0.0044 - val_loss: 0.0018\n",
      "Epoch 16/500\n",
      "222/222 [==============================] - 0s 68us/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 17/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 18/500\n",
      "222/222 [==============================] - 0s 77us/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 19/500\n",
      "222/222 [==============================] - 0s 63us/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 20/500\n",
      "222/222 [==============================] - 0s 57us/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 21/500\n",
      "222/222 [==============================] - 0s 59us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 22/500\n",
      "222/222 [==============================] - 0s 50us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 23/500\n",
      "222/222 [==============================] - 0s 52us/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 24/500\n",
      "222/222 [==============================] - 0s 70us/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 25/500\n",
      "222/222 [==============================] - 0s 49us/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 26/500\n",
      "222/222 [==============================] - 0s 82us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 27/500\n",
      "222/222 [==============================] - 0s 88us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 28/500\n",
      "222/222 [==============================] - 0s 99us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 29/500\n",
      "222/222 [==============================] - 0s 91us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 30/500\n",
      "222/222 [==============================] - 0s 62us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 31/500\n",
      "222/222 [==============================] - 0s 85us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 32/500\n",
      "222/222 [==============================] - 0s 83us/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 33/500\n",
      "222/222 [==============================] - 0s 70us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 34/500\n",
      "222/222 [==============================] - 0s 73us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 35/500\n",
      "222/222 [==============================] - 0s 75us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 36/500\n",
      "222/222 [==============================] - 0s 74us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 37/500\n",
      "222/222 [==============================] - 0s 81us/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 38/500\n",
      "222/222 [==============================] - 0s 97us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 39/500\n",
      "222/222 [==============================] - 0s 76us/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 40/500\n",
      "222/222 [==============================] - 0s 59us/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 41/500\n",
      "222/222 [==============================] - 0s 95us/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 42/500\n",
      "222/222 [==============================] - 0s 81us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 43/500\n",
      "222/222 [==============================] - 0s 83us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 44/500\n",
      "222/222 [==============================] - 0s 72us/step - loss: 9.8778e-04 - val_loss: 0.0025\n",
      "Epoch 45/500\n",
      "222/222 [==============================] - 0s 81us/step - loss: 9.3416e-04 - val_loss: 0.0028\n",
      "Epoch 46/500\n",
      "222/222 [==============================] - 0s 85us/step - loss: 8.4437e-04 - val_loss: 0.0023\n",
      "Epoch 47/500\n",
      "222/222 [==============================] - 0s 97us/step - loss: 8.0405e-04 - val_loss: 0.0028\n",
      "Epoch 48/500\n",
      "222/222 [==============================] - 0s 99us/step - loss: 7.9010e-04 - val_loss: 0.0037\n",
      "Epoch 49/500\n",
      "222/222 [==============================] - 0s 86us/step - loss: 8.5696e-04 - val_loss: 0.0038\n",
      "Epoch 50/500\n",
      "222/222 [==============================] - 0s 73us/step - loss: 7.4273e-04 - val_loss: 0.0032\n",
      "Epoch 51/500\n",
      "222/222 [==============================] - 0s 109us/step - loss: 7.0935e-04 - val_loss: 0.0037\n",
      "Epoch 52/500\n",
      "222/222 [==============================] - 0s 83us/step - loss: 7.1769e-04 - val_loss: 0.0034\n",
      "Epoch 53/500\n",
      "222/222 [==============================] - 0s 66us/step - loss: 7.0190e-04 - val_loss: 0.0040\n",
      "Epoch 54/500\n",
      "222/222 [==============================] - 0s 92us/step - loss: 7.1025e-04 - val_loss: 0.0038\n",
      "Epoch 55/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 6.9876e-04 - val_loss: 0.0038\n",
      "Epoch 56/500\n",
      "222/222 [==============================] - 0s 70us/step - loss: 7.9244e-04 - val_loss: 0.0024\n",
      "Epoch 57/500\n",
      "222/222 [==============================] - 0s 63us/step - loss: 7.1790e-04 - val_loss: 0.0036\n",
      "Epoch 58/500\n",
      "222/222 [==============================] - 0s 65us/step - loss: 6.6436e-04 - val_loss: 0.0026\n",
      "Epoch 59/500\n",
      "222/222 [==============================] - 0s 78us/step - loss: 6.2878e-04 - val_loss: 0.0043\n",
      "Epoch 60/500\n",
      "222/222 [==============================] - 0s 62us/step - loss: 5.4812e-04 - val_loss: 0.0048\n",
      "Epoch 61/500\n",
      "222/222 [==============================] - 0s 66us/step - loss: 7.9844e-04 - val_loss: 0.0061\n",
      "Epoch 62/500\n",
      "222/222 [==============================] - 0s 63us/step - loss: 6.6300e-04 - val_loss: 0.0036\n",
      "Epoch 63/500\n",
      "222/222 [==============================] - 0s 71us/step - loss: 4.8308e-04 - val_loss: 0.0038\n",
      "Epoch 64/500\n",
      "222/222 [==============================] - 0s 58us/step - loss: 4.5877e-04 - val_loss: 0.0044\n",
      "Epoch 65/500\n",
      "222/222 [==============================] - 0s 52us/step - loss: 4.7905e-04 - val_loss: 0.0041\n",
      "Epoch 66/500\n",
      "222/222 [==============================] - 0s 57us/step - loss: 4.6197e-04 - val_loss: 0.0035\n",
      "Epoch 67/500\n",
      "222/222 [==============================] - 0s 63us/step - loss: 5.7502e-04 - val_loss: 0.0029\n",
      "Epoch 68/500\n",
      "222/222 [==============================] - 0s 63us/step - loss: 5.1122e-04 - val_loss: 0.0037\n",
      "Epoch 69/500\n",
      "222/222 [==============================] - 0s 53us/step - loss: 4.8286e-04 - val_loss: 0.0047\n",
      "Epoch 70/500\n",
      "222/222 [==============================] - 0s 53us/step - loss: 4.4865e-04 - val_loss: 0.0061\n",
      "Epoch 71/500\n",
      "222/222 [==============================] - 0s 50us/step - loss: 4.2743e-04 - val_loss: 0.0059\n",
      "Epoch 72/500\n",
      "222/222 [==============================] - 0s 63us/step - loss: 4.3991e-04 - val_loss: 0.0046\n",
      "Epoch 73/500\n",
      "222/222 [==============================] - 0s 61us/step - loss: 3.9603e-04 - val_loss: 0.0034\n",
      "Epoch 74/500\n",
      "222/222 [==============================] - 0s 69us/step - loss: 3.6860e-04 - val_loss: 0.0043\n",
      "Epoch 75/500\n",
      "222/222 [==============================] - 0s 67us/step - loss: 3.3739e-04 - val_loss: 0.0042\n",
      "Epoch 76/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222/222 [==============================] - 0s 67us/step - loss: 3.5503e-04 - val_loss: 0.0044\n",
      "Epoch 77/500\n",
      "222/222 [==============================] - 0s 64us/step - loss: 3.0361e-04 - val_loss: 0.0044\n",
      "Epoch 78/500\n",
      "222/222 [==============================] - 0s 58us/step - loss: 2.9436e-04 - val_loss: 0.0049\n",
      "Epoch 79/500\n",
      "222/222 [==============================] - 0s 69us/step - loss: 2.5242e-04 - val_loss: 0.0049\n",
      "Epoch 80/500\n",
      "222/222 [==============================] - 0s 64us/step - loss: 2.7001e-04 - val_loss: 0.0043\n",
      "Epoch 81/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 2.9259e-04 - val_loss: 0.0053\n",
      "Epoch 82/500\n",
      "222/222 [==============================] - 0s 55us/step - loss: 2.4272e-04 - val_loss: 0.0042\n",
      "Epoch 83/500\n",
      "222/222 [==============================] - 0s 50us/step - loss: 2.8430e-04 - val_loss: 0.0043\n",
      "Epoch 84/500\n",
      "222/222 [==============================] - 0s 53us/step - loss: 3.1961e-04 - val_loss: 0.0040\n",
      "Epoch 85/500\n",
      "222/222 [==============================] - 0s 59us/step - loss: 2.7973e-04 - val_loss: 0.0067\n",
      "Epoch 86/500\n",
      "222/222 [==============================] - 0s 60us/step - loss: 2.3609e-04 - val_loss: 0.0047\n",
      "Epoch 87/500\n",
      "222/222 [==============================] - 0s 57us/step - loss: 2.0401e-04 - val_loss: 0.0047\n",
      "Epoch 88/500\n",
      "222/222 [==============================] - 0s 59us/step - loss: 2.4077e-04 - val_loss: 0.0047\n",
      "Epoch 89/500\n",
      "222/222 [==============================] - 0s 55us/step - loss: 2.0792e-04 - val_loss: 0.0062\n",
      "Epoch 90/500\n",
      "222/222 [==============================] - 0s 55us/step - loss: 2.2434e-04 - val_loss: 0.0054\n",
      "Epoch 91/500\n",
      "222/222 [==============================] - 0s 59us/step - loss: 2.1782e-04 - val_loss: 0.0046\n",
      "Epoch 92/500\n",
      "222/222 [==============================] - 0s 88us/step - loss: 1.9444e-04 - val_loss: 0.0056\n",
      "Epoch 93/500\n",
      "222/222 [==============================] - 0s 49us/step - loss: 1.5804e-04 - val_loss: 0.0055\n",
      "Epoch 94/500\n",
      "222/222 [==============================] - 0s 52us/step - loss: 2.0243e-04 - val_loss: 0.0059\n",
      "Epoch 95/500\n",
      "222/222 [==============================] - 0s 60us/step - loss: 1.6202e-04 - val_loss: 0.0049\n",
      "Epoch 96/500\n",
      "222/222 [==============================] - 0s 63us/step - loss: 1.4471e-04 - val_loss: 0.0059\n",
      "Epoch 97/500\n",
      "222/222 [==============================] - 0s 59us/step - loss: 1.3625e-04 - val_loss: 0.0056\n",
      "Epoch 98/500\n",
      "222/222 [==============================] - 0s 63us/step - loss: 1.6993e-04 - val_loss: 0.0052\n",
      "Epoch 99/500\n",
      "222/222 [==============================] - 0s 53us/step - loss: 2.4687e-04 - val_loss: 0.0044\n",
      "Epoch 100/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 3.2725e-04 - val_loss: 0.0082\n",
      "Epoch 101/500\n",
      "222/222 [==============================] - 0s 61us/step - loss: 2.5584e-04 - val_loss: 0.0055\n",
      "Epoch 102/500\n",
      "222/222 [==============================] - 0s 59us/step - loss: 1.3158e-04 - val_loss: 0.0057\n",
      "Epoch 103/500\n",
      "222/222 [==============================] - 0s 49us/step - loss: 1.3027e-04 - val_loss: 0.0056\n",
      "Epoch 104/500\n",
      "222/222 [==============================] - 0s 55us/step - loss: 1.3390e-04 - val_loss: 0.0051\n",
      "Epoch 105/500\n",
      "222/222 [==============================] - 0s 52us/step - loss: 1.0908e-04 - val_loss: 0.0058\n",
      "Epoch 106/500\n",
      "222/222 [==============================] - 0s 60us/step - loss: 1.0608e-04 - val_loss: 0.0057\n",
      "Epoch 107/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 1.1846e-04 - val_loss: 0.0070\n",
      "Epoch 108/500\n",
      "222/222 [==============================] - 0s 65us/step - loss: 1.0696e-04 - val_loss: 0.0056\n",
      "Epoch 109/500\n",
      "222/222 [==============================] - 0s 72us/step - loss: 8.9208e-05 - val_loss: 0.0057\n",
      "Epoch 110/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 9.4951e-05 - val_loss: 0.0063\n",
      "Epoch 111/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 8.9170e-05 - val_loss: 0.0058\n",
      "Epoch 112/500\n",
      "222/222 [==============================] - 0s 64us/step - loss: 9.1128e-05 - val_loss: 0.0064\n",
      "Epoch 113/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 9.0475e-05 - val_loss: 0.0063\n",
      "Epoch 114/500\n",
      "222/222 [==============================] - 0s 49us/step - loss: 1.0436e-04 - val_loss: 0.0061\n",
      "Epoch 115/500\n",
      "222/222 [==============================] - 0s 60us/step - loss: 9.1643e-05 - val_loss: 0.0059\n",
      "Epoch 116/500\n",
      "222/222 [==============================] - 0s 68us/step - loss: 7.3654e-05 - val_loss: 0.0068\n",
      "Epoch 117/500\n",
      "222/222 [==============================] - 0s 58us/step - loss: 7.4254e-05 - val_loss: 0.0068\n",
      "Epoch 118/500\n",
      "222/222 [==============================] - 0s 58us/step - loss: 1.0678e-04 - val_loss: 0.0067\n",
      "Epoch 119/500\n",
      "222/222 [==============================] - 0s 59us/step - loss: 1.1153e-04 - val_loss: 0.0063\n",
      "Epoch 120/500\n",
      "222/222 [==============================] - 0s 51us/step - loss: 9.9738e-05 - val_loss: 0.0078\n",
      "Epoch 121/500\n",
      "222/222 [==============================] - 0s 57us/step - loss: 6.9726e-05 - val_loss: 0.0063\n",
      "Epoch 122/500\n",
      "222/222 [==============================] - 0s 61us/step - loss: 7.0471e-05 - val_loss: 0.0067\n",
      "Epoch 123/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 6.6640e-05 - val_loss: 0.0065\n",
      "Epoch 124/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 7.1086e-05 - val_loss: 0.0074\n",
      "Epoch 125/500\n",
      "222/222 [==============================] - 0s 58us/step - loss: 6.0728e-05 - val_loss: 0.0072\n",
      "Epoch 126/500\n",
      "222/222 [==============================] - 0s 78us/step - loss: 6.5771e-05 - val_loss: 0.0063\n",
      "Epoch 127/500\n",
      "222/222 [==============================] - 0s 51us/step - loss: 5.4569e-05 - val_loss: 0.0076\n",
      "Epoch 128/500\n",
      "222/222 [==============================] - 0s 64us/step - loss: 5.1544e-05 - val_loss: 0.0071\n",
      "Epoch 129/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 5.1738e-05 - val_loss: 0.0069\n",
      "Epoch 130/500\n",
      "222/222 [==============================] - 0s 59us/step - loss: 4.5331e-05 - val_loss: 0.0074\n",
      "Epoch 131/500\n",
      "222/222 [==============================] - 0s 53us/step - loss: 5.0070e-05 - val_loss: 0.0078\n",
      "Epoch 132/500\n",
      "222/222 [==============================] - 0s 57us/step - loss: 4.3730e-05 - val_loss: 0.0076\n",
      "Epoch 133/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 5.3159e-05 - val_loss: 0.0072\n",
      "Epoch 134/500\n",
      "222/222 [==============================] - 0s 57us/step - loss: 4.9732e-05 - val_loss: 0.0080\n",
      "Epoch 135/500\n",
      "222/222 [==============================] - 0s 50us/step - loss: 3.9374e-05 - val_loss: 0.0070\n",
      "Epoch 136/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 4.2762e-05 - val_loss: 0.0079\n",
      "Epoch 137/500\n",
      "222/222 [==============================] - 0s 60us/step - loss: 4.0998e-05 - val_loss: 0.0073\n",
      "Epoch 138/500\n",
      "222/222 [==============================] - 0s 63us/step - loss: 3.8852e-05 - val_loss: 0.0077\n",
      "Epoch 139/500\n",
      "222/222 [==============================] - 0s 53us/step - loss: 5.1682e-05 - val_loss: 0.0080\n",
      "Epoch 140/500\n",
      "222/222 [==============================] - 0s 57us/step - loss: 6.1579e-05 - val_loss: 0.0070\n",
      "Epoch 141/500\n",
      "222/222 [==============================] - 0s 59us/step - loss: 8.0138e-05 - val_loss: 0.0072\n",
      "Epoch 142/500\n",
      "222/222 [==============================] - 0s 55us/step - loss: 1.0005e-04 - val_loss: 0.0081\n",
      "Epoch 143/500\n",
      "222/222 [==============================] - 0s 57us/step - loss: 5.6176e-05 - val_loss: 0.0076\n",
      "Epoch 144/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 4.3998e-05 - val_loss: 0.0070\n",
      "Epoch 145/500\n",
      "222/222 [==============================] - 0s 55us/step - loss: 3.9817e-05 - val_loss: 0.0084\n",
      "Epoch 146/500\n",
      "222/222 [==============================] - 0s 59us/step - loss: 3.6587e-05 - val_loss: 0.0071\n",
      "Epoch 147/500\n",
      "222/222 [==============================] - 0s 55us/step - loss: 6.3775e-05 - val_loss: 0.0086\n",
      "Epoch 148/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 4.5348e-05 - val_loss: 0.0076\n",
      "Epoch 149/500\n",
      "222/222 [==============================] - 0s 60us/step - loss: 4.3228e-05 - val_loss: 0.0081\n",
      "Epoch 150/500\n",
      "222/222 [==============================] - 0s 63us/step - loss: 4.3518e-05 - val_loss: 0.0081\n",
      "Epoch 151/500\n",
      "222/222 [==============================] - 0s 67us/step - loss: 3.3432e-05 - val_loss: 0.0081\n",
      "Epoch 152/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222/222 [==============================] - 0s 54us/step - loss: 3.3160e-05 - val_loss: 0.0082\n",
      "Epoch 153/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 2.5731e-05 - val_loss: 0.0086\n",
      "Epoch 154/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 3.3449e-05 - val_loss: 0.0080\n",
      "Epoch 155/500\n",
      "222/222 [==============================] - 0s 79us/step - loss: 5.8493e-05 - val_loss: 0.0082\n",
      "Epoch 156/500\n",
      "222/222 [==============================] - 0s 61us/step - loss: 6.4083e-05 - val_loss: 0.0077\n",
      "Epoch 157/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 8.1573e-05 - val_loss: 0.0080\n",
      "Epoch 158/500\n",
      "222/222 [==============================] - 0s 62us/step - loss: 5.5482e-05 - val_loss: 0.0084\n",
      "Epoch 159/500\n",
      "222/222 [==============================] - 0s 58us/step - loss: 2.5681e-05 - val_loss: 0.0081\n",
      "Epoch 160/500\n",
      "222/222 [==============================] - 0s 58us/step - loss: 1.9594e-05 - val_loss: 0.0079\n",
      "Epoch 161/500\n",
      "222/222 [==============================] - 0s 58us/step - loss: 2.4330e-05 - val_loss: 0.0093\n",
      "Epoch 162/500\n",
      "222/222 [==============================] - 0s 55us/step - loss: 2.7205e-05 - val_loss: 0.0082\n",
      "Epoch 163/500\n",
      "222/222 [==============================] - 0s 58us/step - loss: 2.1775e-05 - val_loss: 0.0084\n",
      "Epoch 164/500\n",
      "222/222 [==============================] - 0s 50us/step - loss: 1.5670e-05 - val_loss: 0.0085\n",
      "Epoch 165/500\n",
      "222/222 [==============================] - 0s 57us/step - loss: 1.3033e-05 - val_loss: 0.0083\n",
      "Epoch 166/500\n",
      "222/222 [==============================] - 0s 65us/step - loss: 1.4343e-05 - val_loss: 0.0086\n",
      "Epoch 167/500\n",
      "222/222 [==============================] - 0s 55us/step - loss: 1.1975e-05 - val_loss: 0.0082\n",
      "Epoch 168/500\n",
      "222/222 [==============================] - 0s 55us/step - loss: 1.4255e-05 - val_loss: 0.0087\n",
      "Epoch 169/500\n",
      "222/222 [==============================] - 0s 62us/step - loss: 1.4080e-05 - val_loss: 0.0086\n",
      "Epoch 170/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 2.3438e-05 - val_loss: 0.0089\n",
      "Epoch 171/500\n",
      "222/222 [==============================] - 0s 69us/step - loss: 2.3112e-05 - val_loss: 0.0079\n",
      "Epoch 172/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 1.4224e-05 - val_loss: 0.0095\n",
      "Epoch 173/500\n",
      "222/222 [==============================] - 0s 52us/step - loss: 1.1567e-05 - val_loss: 0.0085\n",
      "Epoch 174/500\n",
      "222/222 [==============================] - 0s 59us/step - loss: 9.6656e-06 - val_loss: 0.0084\n",
      "Epoch 175/500\n",
      "222/222 [==============================] - 0s 53us/step - loss: 9.5202e-06 - val_loss: 0.0088\n",
      "Epoch 176/500\n",
      "222/222 [==============================] - 0s 53us/step - loss: 1.2149e-05 - val_loss: 0.0084\n",
      "Epoch 177/500\n",
      "222/222 [==============================] - 0s 53us/step - loss: 1.1559e-05 - val_loss: 0.0084\n",
      "Epoch 178/500\n",
      "222/222 [==============================] - 0s 60us/step - loss: 1.0445e-05 - val_loss: 0.0092\n",
      "Epoch 179/500\n",
      "222/222 [==============================] - 0s 69us/step - loss: 9.4811e-06 - val_loss: 0.0086\n",
      "Epoch 180/500\n",
      "222/222 [==============================] - 0s 49us/step - loss: 8.5791e-06 - val_loss: 0.0086\n",
      "Epoch 181/500\n",
      "222/222 [==============================] - 0s 55us/step - loss: 7.2774e-06 - val_loss: 0.0090\n",
      "Epoch 182/500\n",
      "222/222 [==============================] - 0s 57us/step - loss: 6.9631e-06 - val_loss: 0.0089\n",
      "Epoch 183/500\n",
      "222/222 [==============================] - 0s 61us/step - loss: 8.9535e-06 - val_loss: 0.0084\n",
      "Epoch 184/500\n",
      "222/222 [==============================] - 0s 61us/step - loss: 7.9416e-06 - val_loss: 0.0090\n",
      "Epoch 185/500\n",
      "222/222 [==============================] - 0s 64us/step - loss: 6.6095e-06 - val_loss: 0.0092\n",
      "Epoch 186/500\n",
      "222/222 [==============================] - 0s 51us/step - loss: 8.6347e-06 - val_loss: 0.0089\n",
      "Epoch 187/500\n",
      "222/222 [==============================] - 0s 55us/step - loss: 5.8229e-06 - val_loss: 0.0088\n",
      "Epoch 188/500\n",
      "222/222 [==============================] - 0s 52us/step - loss: 5.6702e-06 - val_loss: 0.0094\n",
      "Epoch 189/500\n",
      "222/222 [==============================] - 0s 61us/step - loss: 6.5611e-06 - val_loss: 0.0091\n",
      "Epoch 190/500\n",
      "222/222 [==============================] - 0s 67us/step - loss: 5.3772e-06 - val_loss: 0.0088\n",
      "Epoch 191/500\n",
      "222/222 [==============================] - 0s 52us/step - loss: 9.4129e-06 - val_loss: 0.0094\n",
      "Epoch 192/500\n",
      "222/222 [==============================] - 0s 58us/step - loss: 7.1315e-06 - val_loss: 0.0092\n",
      "Epoch 193/500\n",
      "222/222 [==============================] - 0s 53us/step - loss: 8.5215e-06 - val_loss: 0.0091\n",
      "Epoch 194/500\n",
      "222/222 [==============================] - 0s 63us/step - loss: 5.7068e-06 - val_loss: 0.0096\n",
      "Epoch 195/500\n",
      "222/222 [==============================] - 0s 58us/step - loss: 5.2580e-06 - val_loss: 0.0091\n",
      "Epoch 196/500\n",
      "222/222 [==============================] - 0s 50us/step - loss: 5.1405e-06 - val_loss: 0.0091\n",
      "Epoch 197/500\n",
      "222/222 [==============================] - 0s 53us/step - loss: 5.3635e-06 - val_loss: 0.0097\n",
      "Epoch 198/500\n",
      "222/222 [==============================] - 0s 49us/step - loss: 7.7523e-06 - val_loss: 0.0093\n",
      "Epoch 199/500\n",
      "222/222 [==============================] - 0s 60us/step - loss: 8.0253e-06 - val_loss: 0.0092\n",
      "Epoch 200/500\n",
      "222/222 [==============================] - 0s 59us/step - loss: 9.0935e-06 - val_loss: 0.0086\n",
      "Epoch 201/500\n",
      "222/222 [==============================] - 0s 66us/step - loss: 1.2750e-05 - val_loss: 0.0088\n",
      "Epoch 202/500\n",
      "222/222 [==============================] - 0s 65us/step - loss: 1.2427e-05 - val_loss: 0.0092\n",
      "Epoch 203/500\n",
      "222/222 [==============================] - 0s 61us/step - loss: 7.3715e-06 - val_loss: 0.0094\n",
      "Epoch 204/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 5.4820e-06 - val_loss: 0.0096\n",
      "Epoch 205/500\n",
      "222/222 [==============================] - 0s 53us/step - loss: 4.5998e-06 - val_loss: 0.0094\n",
      "Epoch 206/500\n",
      "222/222 [==============================] - 0s 50us/step - loss: 6.5086e-06 - val_loss: 0.0094\n",
      "Epoch 207/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 4.3719e-06 - val_loss: 0.0094\n",
      "Epoch 208/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 2.8476e-06 - val_loss: 0.0093\n",
      "Epoch 209/500\n",
      "222/222 [==============================] - 0s 57us/step - loss: 3.5426e-06 - val_loss: 0.0096\n",
      "Epoch 210/500\n",
      "222/222 [==============================] - 0s 55us/step - loss: 3.9306e-06 - val_loss: 0.0095\n",
      "Epoch 211/500\n",
      "222/222 [==============================] - 0s 58us/step - loss: 3.2774e-06 - val_loss: 0.0095\n",
      "Epoch 212/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 2.4418e-06 - val_loss: 0.0095\n",
      "Epoch 213/500\n",
      "222/222 [==============================] - 0s 57us/step - loss: 2.4089e-06 - val_loss: 0.0094\n",
      "Epoch 214/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 3.9353e-06 - val_loss: 0.0095\n",
      "Epoch 215/500\n",
      "222/222 [==============================] - 0s 62us/step - loss: 3.3890e-06 - val_loss: 0.0094\n",
      "Epoch 216/500\n",
      "222/222 [==============================] - 0s 55us/step - loss: 3.5234e-06 - val_loss: 0.0095\n",
      "Epoch 217/500\n",
      "222/222 [==============================] - 0s 58us/step - loss: 2.8074e-06 - val_loss: 0.0094\n",
      "Epoch 218/500\n",
      "222/222 [==============================] - 0s 53us/step - loss: 3.3734e-06 - val_loss: 0.0096\n",
      "Epoch 219/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 3.7486e-06 - val_loss: 0.0096\n",
      "Epoch 220/500\n",
      "222/222 [==============================] - 0s 57us/step - loss: 3.4051e-06 - val_loss: 0.0094\n",
      "Epoch 221/500\n",
      "222/222 [==============================] - 0s 61us/step - loss: 4.5185e-06 - val_loss: 0.0096\n",
      "Epoch 222/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 2.7584e-06 - val_loss: 0.0099\n",
      "Epoch 223/500\n",
      "222/222 [==============================] - 0s 55us/step - loss: 3.1261e-06 - val_loss: 0.0098\n",
      "Epoch 224/500\n",
      "222/222 [==============================] - 0s 63us/step - loss: 4.2157e-06 - val_loss: 0.0098\n",
      "Epoch 225/500\n",
      "222/222 [==============================] - 0s 60us/step - loss: 2.6420e-06 - val_loss: 0.0099\n",
      "Epoch 226/500\n",
      "222/222 [==============================] - 0s 71us/step - loss: 1.4833e-06 - val_loss: 0.0096\n",
      "Epoch 227/500\n",
      "222/222 [==============================] - 0s 68us/step - loss: 1.5552e-06 - val_loss: 0.0095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 228/500\n",
      "222/222 [==============================] - 0s 63us/step - loss: 2.0405e-06 - val_loss: 0.0094\n",
      "Epoch 229/500\n",
      "222/222 [==============================] - 0s 57us/step - loss: 3.6375e-06 - val_loss: 0.0094\n",
      "Epoch 230/500\n",
      "222/222 [==============================] - 0s 61us/step - loss: 2.4438e-06 - val_loss: 0.0098\n",
      "Epoch 231/500\n",
      "222/222 [==============================] - 0s 59us/step - loss: 3.4074e-06 - val_loss: 0.0096\n",
      "Epoch 232/500\n",
      "222/222 [==============================] - 0s 51us/step - loss: 2.6778e-06 - val_loss: 0.0096\n",
      "Epoch 233/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 3.1091e-06 - val_loss: 0.0098\n",
      "Epoch 234/500\n",
      "222/222 [==============================] - 0s 58us/step - loss: 4.2222e-06 - val_loss: 0.0096\n",
      "Epoch 235/500\n",
      "222/222 [==============================] - 0s 49us/step - loss: 2.1743e-06 - val_loss: 0.0099\n",
      "Epoch 236/500\n",
      "222/222 [==============================] - 0s 61us/step - loss: 1.1630e-06 - val_loss: 0.0100\n",
      "Epoch 237/500\n",
      "222/222 [==============================] - 0s 61us/step - loss: 1.5838e-06 - val_loss: 0.0098\n",
      "Epoch 238/500\n",
      "222/222 [==============================] - 0s 60us/step - loss: 2.9740e-06 - val_loss: 0.0100\n",
      "Epoch 239/500\n",
      "222/222 [==============================] - 0s 61us/step - loss: 2.4140e-06 - val_loss: 0.0096\n",
      "Epoch 240/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 1.4505e-06 - val_loss: 0.0097\n",
      "Epoch 241/500\n",
      "222/222 [==============================] - 0s 58us/step - loss: 1.2493e-06 - val_loss: 0.0100\n",
      "Epoch 242/500\n",
      "222/222 [==============================] - 0s 51us/step - loss: 1.3903e-06 - val_loss: 0.0100\n",
      "Epoch 243/500\n",
      "222/222 [==============================] - 0s 61us/step - loss: 1.7410e-06 - val_loss: 0.0099\n",
      "Epoch 244/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 1.2833e-06 - val_loss: 0.0100\n",
      "Epoch 245/500\n",
      "222/222 [==============================] - 0s 58us/step - loss: 7.1195e-07 - val_loss: 0.0099\n",
      "Epoch 246/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 1.0170e-06 - val_loss: 0.0098\n",
      "Epoch 247/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 8.4406e-07 - val_loss: 0.0099\n",
      "Epoch 248/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 7.4657e-07 - val_loss: 0.0100\n",
      "Epoch 249/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 7.8578e-07 - val_loss: 0.0100\n",
      "Epoch 250/500\n",
      "222/222 [==============================] - 0s 55us/step - loss: 9.4138e-07 - val_loss: 0.0100\n",
      "Epoch 251/500\n",
      "222/222 [==============================] - 0s 60us/step - loss: 1.9572e-06 - val_loss: 0.0102\n",
      "Epoch 252/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 1.4472e-06 - val_loss: 0.0100\n",
      "Epoch 253/500\n",
      "222/222 [==============================] - 0s 64us/step - loss: 8.0883e-07 - val_loss: 0.0098\n",
      "Epoch 254/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 7.3775e-07 - val_loss: 0.0099\n",
      "Epoch 255/500\n",
      "222/222 [==============================] - 0s 65us/step - loss: 6.8876e-07 - val_loss: 0.0099\n",
      "Epoch 256/500\n",
      "222/222 [==============================] - 0s 53us/step - loss: 5.3493e-07 - val_loss: 0.0101\n",
      "Epoch 257/500\n",
      "222/222 [==============================] - 0s 58us/step - loss: 5.4924e-07 - val_loss: 0.0102\n",
      "Epoch 258/500\n",
      "222/222 [==============================] - 0s 58us/step - loss: 5.6740e-07 - val_loss: 0.0099\n",
      "Epoch 259/500\n",
      "222/222 [==============================] - 0s 62us/step - loss: 6.2826e-07 - val_loss: 0.0100\n",
      "Epoch 260/500\n",
      "222/222 [==============================] - 0s 64us/step - loss: 9.7691e-07 - val_loss: 0.0101\n",
      "Epoch 261/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 1.3903e-06 - val_loss: 0.0100\n",
      "Epoch 262/500\n",
      "222/222 [==============================] - 0s 53us/step - loss: 9.6772e-07 - val_loss: 0.0101\n",
      "Epoch 263/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 6.7453e-07 - val_loss: 0.0102\n",
      "Epoch 264/500\n",
      "222/222 [==============================] - 0s 64us/step - loss: 9.9747e-07 - val_loss: 0.0102\n",
      "Epoch 265/500\n",
      "222/222 [==============================] - 0s 67us/step - loss: 6.4272e-07 - val_loss: 0.0102\n",
      "Epoch 266/500\n",
      "222/222 [==============================] - 0s 53us/step - loss: 9.2345e-07 - val_loss: 0.0101\n",
      "Epoch 267/500\n",
      "222/222 [==============================] - 0s 55us/step - loss: 6.9768e-07 - val_loss: 0.0101\n",
      "Epoch 268/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 1.2213e-06 - val_loss: 0.0102\n",
      "Epoch 269/500\n",
      "222/222 [==============================] - 0s 60us/step - loss: 1.9226e-06 - val_loss: 0.0104\n",
      "Epoch 270/500\n",
      "222/222 [==============================] - 0s 58us/step - loss: 1.5599e-06 - val_loss: 0.0102\n",
      "Epoch 271/500\n",
      "222/222 [==============================] - 0s 60us/step - loss: 1.5943e-06 - val_loss: 0.0101\n",
      "Epoch 272/500\n",
      "222/222 [==============================] - 0s 66us/step - loss: 2.0228e-06 - val_loss: 0.0103\n",
      "Epoch 273/500\n",
      "222/222 [==============================] - 0s 58us/step - loss: 6.8960e-07 - val_loss: 0.0102\n",
      "Epoch 274/500\n",
      "222/222 [==============================] - 0s 57us/step - loss: 8.2305e-07 - val_loss: 0.0102\n",
      "Epoch 275/500\n",
      "222/222 [==============================] - 0s 65us/step - loss: 6.7305e-07 - val_loss: 0.0102\n",
      "Epoch 276/500\n",
      "222/222 [==============================] - 0s 62us/step - loss: 6.2296e-07 - val_loss: 0.0101\n",
      "Epoch 277/500\n",
      "222/222 [==============================] - 0s 58us/step - loss: 5.5866e-07 - val_loss: 0.0102\n",
      "Epoch 278/500\n",
      "222/222 [==============================] - 0s 59us/step - loss: 4.8676e-07 - val_loss: 0.0100\n",
      "Epoch 279/500\n",
      "222/222 [==============================] - 0s 53us/step - loss: 5.5695e-07 - val_loss: 0.0104\n",
      "Epoch 280/500\n",
      "222/222 [==============================] - 0s 66us/step - loss: 4.4890e-07 - val_loss: 0.0103\n",
      "Epoch 281/500\n",
      "222/222 [==============================] - 0s 62us/step - loss: 3.1250e-07 - val_loss: 0.0101\n",
      "Epoch 282/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 3.8022e-07 - val_loss: 0.0101\n",
      "Epoch 283/500\n",
      "222/222 [==============================] - 0s 53us/step - loss: 8.7349e-07 - val_loss: 0.0103\n",
      "Epoch 284/500\n",
      "222/222 [==============================] - 0s 55us/step - loss: 8.0555e-07 - val_loss: 0.0100\n",
      "Epoch 285/500\n",
      "222/222 [==============================] - 0s 62us/step - loss: 3.9416e-07 - val_loss: 0.0103\n",
      "Epoch 286/500\n",
      "222/222 [==============================] - 0s 62us/step - loss: 4.7442e-07 - val_loss: 0.0104\n",
      "Epoch 287/500\n",
      "222/222 [==============================] - 0s 61us/step - loss: 2.5328e-07 - val_loss: 0.0102\n",
      "Epoch 288/500\n",
      "222/222 [==============================] - 0s 61us/step - loss: 3.8901e-07 - val_loss: 0.0102\n",
      "Epoch 289/500\n",
      "222/222 [==============================] - 0s 53us/step - loss: 3.3346e-07 - val_loss: 0.0102\n",
      "Epoch 290/500\n",
      "222/222 [==============================] - 0s 53us/step - loss: 3.1510e-07 - val_loss: 0.0101\n",
      "Epoch 291/500\n",
      "222/222 [==============================] - 0s 52us/step - loss: 2.7170e-07 - val_loss: 0.0102\n",
      "Epoch 292/500\n",
      "222/222 [==============================] - 0s 53us/step - loss: 4.8467e-07 - val_loss: 0.0103\n",
      "Epoch 293/500\n",
      "222/222 [==============================] - 0s 62us/step - loss: 7.2487e-07 - val_loss: 0.0100\n",
      "Epoch 294/500\n",
      "222/222 [==============================] - 0s 67us/step - loss: 8.0845e-07 - val_loss: 0.0102\n",
      "Epoch 295/500\n",
      "222/222 [==============================] - 0s 59us/step - loss: 6.8704e-07 - val_loss: 0.0102\n",
      "Epoch 296/500\n",
      "222/222 [==============================] - 0s 62us/step - loss: 5.8871e-07 - val_loss: 0.0104\n",
      "Epoch 297/500\n",
      "222/222 [==============================] - 0s 59us/step - loss: 4.0853e-07 - val_loss: 0.0103\n",
      "Epoch 298/500\n",
      "222/222 [==============================] - 0s 55us/step - loss: 6.2881e-07 - val_loss: 0.0104\n",
      "Epoch 299/500\n",
      "222/222 [==============================] - 0s 58us/step - loss: 7.7804e-07 - val_loss: 0.0103\n",
      "Epoch 300/500\n",
      "222/222 [==============================] - 0s 69us/step - loss: 7.7370e-07 - val_loss: 0.0104\n",
      "Epoch 301/500\n",
      "222/222 [==============================] - 0s 66us/step - loss: 8.1010e-07 - val_loss: 0.0105\n",
      "Epoch 302/500\n",
      "222/222 [==============================] - 0s 60us/step - loss: 7.7103e-07 - val_loss: 0.0103\n",
      "Epoch 303/500\n",
      "222/222 [==============================] - 0s 53us/step - loss: 1.4540e-06 - val_loss: 0.0106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 304/500\n",
      "222/222 [==============================] - 0s 59us/step - loss: 1.0205e-06 - val_loss: 0.0105\n",
      "Epoch 305/500\n",
      "222/222 [==============================] - 0s 53us/step - loss: 5.8804e-07 - val_loss: 0.0103\n",
      "Epoch 306/500\n",
      "222/222 [==============================] - 0s 52us/step - loss: 8.5287e-07 - val_loss: 0.0104\n",
      "Epoch 307/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 1.4895e-06 - val_loss: 0.0101\n",
      "Epoch 308/500\n",
      "222/222 [==============================] - 0s 57us/step - loss: 4.9197e-07 - val_loss: 0.0103\n",
      "Epoch 309/500\n",
      "222/222 [==============================] - 0s 65us/step - loss: 1.0200e-06 - val_loss: 0.0101\n",
      "Epoch 310/500\n",
      "222/222 [==============================] - 0s 51us/step - loss: 7.2043e-07 - val_loss: 0.0102\n",
      "Epoch 311/500\n",
      "222/222 [==============================] - 0s 47us/step - loss: 2.4023e-07 - val_loss: 0.0101\n",
      "Epoch 312/500\n",
      "222/222 [==============================] - 0s 44us/step - loss: 2.0968e-07 - val_loss: 0.0102\n",
      "Epoch 313/500\n",
      "222/222 [==============================] - 0s 48us/step - loss: 3.9140e-07 - val_loss: 0.0103\n",
      "Epoch 314/500\n",
      "222/222 [==============================] - 0s 47us/step - loss: 1.0690e-07 - val_loss: 0.0102\n",
      "Epoch 315/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 1.4099e-07 - val_loss: 0.0101\n",
      "Epoch 316/500\n",
      "222/222 [==============================] - 0s 57us/step - loss: 5.0488e-07 - val_loss: 0.0104\n",
      "Epoch 317/500\n",
      "222/222 [==============================] - 0s 55us/step - loss: 1.6485e-06 - val_loss: 0.0103\n",
      "Epoch 318/500\n",
      "222/222 [==============================] - 0s 58us/step - loss: 5.7264e-07 - val_loss: 0.0102\n",
      "Epoch 319/500\n",
      "222/222 [==============================] - 0s 64us/step - loss: 5.4174e-07 - val_loss: 0.0104\n",
      "Epoch 320/500\n",
      "222/222 [==============================] - 0s 57us/step - loss: 6.5935e-07 - val_loss: 0.0103\n",
      "Epoch 321/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 8.8754e-07 - val_loss: 0.0102\n",
      "Epoch 322/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 8.1952e-07 - val_loss: 0.0101\n",
      "Epoch 323/500\n",
      "222/222 [==============================] - 0s 58us/step - loss: 1.8087e-06 - val_loss: 0.0106\n",
      "Epoch 324/500\n",
      "222/222 [==============================] - 0s 60us/step - loss: 4.6072e-06 - val_loss: 0.0105\n",
      "Epoch 325/500\n",
      "222/222 [==============================] - 0s 52us/step - loss: 2.8101e-06 - val_loss: 0.0107\n",
      "Epoch 326/500\n",
      "222/222 [==============================] - 0s 53us/step - loss: 1.8461e-06 - val_loss: 0.0103\n",
      "Epoch 327/500\n",
      "222/222 [==============================] - 0s 52us/step - loss: 5.6421e-06 - val_loss: 0.0099\n",
      "Epoch 328/500\n",
      "222/222 [==============================] - 0s 64us/step - loss: 6.2095e-06 - val_loss: 0.0111\n",
      "Epoch 329/500\n",
      "222/222 [==============================] - 0s 62us/step - loss: 4.0253e-05 - val_loss: 0.0116\n",
      "Epoch 330/500\n",
      "222/222 [==============================] - 0s 52us/step - loss: 2.8125e-05 - val_loss: 0.0115\n",
      "Epoch 331/500\n",
      "222/222 [==============================] - 0s 52us/step - loss: 5.4946e-06 - val_loss: 0.0105\n",
      "Epoch 332/500\n",
      "222/222 [==============================] - 0s 52us/step - loss: 5.1349e-06 - val_loss: 0.0103\n",
      "Epoch 333/500\n",
      "222/222 [==============================] - 0s 73us/step - loss: 6.4854e-06 - val_loss: 0.0104\n",
      "Epoch 334/500\n",
      "222/222 [==============================] - 0s 59us/step - loss: 2.9070e-05 - val_loss: 0.0103\n",
      "Epoch 335/500\n",
      "222/222 [==============================] - 0s 55us/step - loss: 3.4180e-05 - val_loss: 0.0107\n",
      "Epoch 336/500\n",
      "222/222 [==============================] - 0s 57us/step - loss: 3.1812e-05 - val_loss: 0.0111\n",
      "Epoch 337/500\n",
      "222/222 [==============================] - 0s 53us/step - loss: 2.1955e-05 - val_loss: 0.0106\n",
      "Epoch 338/500\n",
      "222/222 [==============================] - 0s 50us/step - loss: 3.1376e-05 - val_loss: 0.0104\n",
      "Epoch 339/500\n",
      "222/222 [==============================] - 0s 53us/step - loss: 4.6089e-05 - val_loss: 0.0096\n",
      "Epoch 340/500\n",
      "222/222 [==============================] - 0s 62us/step - loss: 5.4273e-05 - val_loss: 0.0086\n",
      "Epoch 341/500\n",
      "222/222 [==============================] - 0s 68us/step - loss: 6.6241e-05 - val_loss: 0.0112\n",
      "Epoch 342/500\n",
      "222/222 [==============================] - 0s 61us/step - loss: 2.1472e-05 - val_loss: 0.0109\n",
      "Epoch 343/500\n",
      "222/222 [==============================] - 0s 63us/step - loss: 2.1600e-05 - val_loss: 0.0113\n",
      "Epoch 344/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 1.1702e-04 - val_loss: 0.0123\n",
      "Epoch 345/500\n",
      "222/222 [==============================] - 0s 55us/step - loss: 1.9186e-04 - val_loss: 0.0100\n",
      "Epoch 346/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 3.0838e-04 - val_loss: 0.0130\n",
      "Epoch 347/500\n",
      "222/222 [==============================] - 0s 96us/step - loss: 2.1764e-04 - val_loss: 0.0094\n",
      "Epoch 348/500\n",
      "222/222 [==============================] - 0s 67us/step - loss: 3.7163e-04 - val_loss: 0.0126\n",
      "Epoch 349/500\n",
      "222/222 [==============================] - 0s 68us/step - loss: 2.5900e-04 - val_loss: 0.0068\n",
      "Epoch 350/500\n",
      "222/222 [==============================] - 0s 61us/step - loss: 3.9309e-04 - val_loss: 0.0097\n",
      "Epoch 351/500\n",
      "222/222 [==============================] - 0s 58us/step - loss: 1.5379e-04 - val_loss: 0.0113\n",
      "Epoch 352/500\n",
      "222/222 [==============================] - 0s 58us/step - loss: 1.3749e-04 - val_loss: 0.0093\n",
      "Epoch 353/500\n",
      "222/222 [==============================] - 0s 52us/step - loss: 2.3637e-04 - val_loss: 0.0115\n",
      "Epoch 354/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 1.5045e-04 - val_loss: 0.0089\n",
      "Epoch 355/500\n",
      "222/222 [==============================] - 0s 58us/step - loss: 1.3618e-04 - val_loss: 0.0078\n",
      "Epoch 356/500\n",
      "222/222 [==============================] - 0s 60us/step - loss: 4.8514e-05 - val_loss: 0.0081\n",
      "Epoch 357/500\n",
      "222/222 [==============================] - 0s 59us/step - loss: 5.3759e-05 - val_loss: 0.0110\n",
      "Epoch 358/500\n",
      "222/222 [==============================] - 0s 60us/step - loss: 4.2957e-05 - val_loss: 0.0122\n",
      "Epoch 359/500\n",
      "222/222 [==============================] - 0s 62us/step - loss: 6.9925e-05 - val_loss: 0.0095\n",
      "Epoch 360/500\n",
      "222/222 [==============================] - 0s 66us/step - loss: 1.4175e-04 - val_loss: 0.0135\n",
      "Epoch 361/500\n",
      "222/222 [==============================] - 0s 61us/step - loss: 1.3339e-04 - val_loss: 0.0097\n",
      "Epoch 362/500\n",
      "222/222 [==============================] - 0s 52us/step - loss: 1.1074e-04 - val_loss: 0.0118\n",
      "Epoch 363/500\n",
      "222/222 [==============================] - 0s 52us/step - loss: 3.9569e-05 - val_loss: 0.0127\n",
      "Epoch 364/500\n",
      "222/222 [==============================] - 0s 55us/step - loss: 1.4903e-04 - val_loss: 0.0120\n",
      "Epoch 365/500\n",
      "222/222 [==============================] - 0s 53us/step - loss: 1.5827e-04 - val_loss: 0.0073\n",
      "Epoch 366/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 2.3887e-04 - val_loss: 0.0107\n",
      "Epoch 367/500\n",
      "222/222 [==============================] - 0s 58us/step - loss: 2.3594e-04 - val_loss: 0.0113\n",
      "Epoch 368/500\n",
      "222/222 [==============================] - 0s 58us/step - loss: 1.5718e-04 - val_loss: 0.0095\n",
      "Epoch 369/500\n",
      "222/222 [==============================] - 0s 57us/step - loss: 1.9408e-04 - val_loss: 0.0107\n",
      "Epoch 370/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 3.1960e-04 - val_loss: 0.0118\n",
      "Epoch 371/500\n",
      "222/222 [==============================] - 0s 51us/step - loss: 4.6583e-04 - val_loss: 0.0145\n",
      "Epoch 372/500\n",
      "222/222 [==============================] - 0s 63us/step - loss: 2.8765e-04 - val_loss: 0.0125\n",
      "Epoch 373/500\n",
      "222/222 [==============================] - 0s 58us/step - loss: 7.5135e-05 - val_loss: 0.0117\n",
      "Epoch 374/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 4.5113e-05 - val_loss: 0.0101\n",
      "Epoch 375/500\n",
      "222/222 [==============================] - 0s 61us/step - loss: 2.1726e-05 - val_loss: 0.0104\n",
      "Epoch 376/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 1.5231e-05 - val_loss: 0.0115\n",
      "Epoch 377/500\n",
      "222/222 [==============================] - 0s 59us/step - loss: 1.6647e-05 - val_loss: 0.0120\n",
      "Epoch 378/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 1.4934e-05 - val_loss: 0.0117\n",
      "Epoch 379/500\n",
      "222/222 [==============================] - 0s 57us/step - loss: 1.3179e-05 - val_loss: 0.0104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 380/500\n",
      "222/222 [==============================] - 0s 63us/step - loss: 6.1701e-06 - val_loss: 0.0105\n",
      "Epoch 381/500\n",
      "222/222 [==============================] - 0s 62us/step - loss: 5.4552e-06 - val_loss: 0.0107\n",
      "Epoch 382/500\n",
      "222/222 [==============================] - 0s 61us/step - loss: 5.1794e-06 - val_loss: 0.0107\n",
      "Epoch 383/500\n",
      "222/222 [==============================] - 0s 58us/step - loss: 2.9531e-06 - val_loss: 0.0107\n",
      "Epoch 384/500\n",
      "222/222 [==============================] - 0s 50us/step - loss: 2.2998e-06 - val_loss: 0.0107\n",
      "Epoch 385/500\n",
      "222/222 [==============================] - 0s 50us/step - loss: 4.3075e-06 - val_loss: 0.0110\n",
      "Epoch 386/500\n",
      "222/222 [==============================] - 0s 59us/step - loss: 1.3882e-05 - val_loss: 0.0107\n",
      "Epoch 387/500\n",
      "222/222 [==============================] - 0s 52us/step - loss: 1.9410e-05 - val_loss: 0.0106\n",
      "Epoch 388/500\n",
      "222/222 [==============================] - 0s 65us/step - loss: 6.0200e-06 - val_loss: 0.0103\n",
      "Epoch 389/500\n",
      "222/222 [==============================] - 0s 51us/step - loss: 6.4364e-06 - val_loss: 0.0108\n",
      "Epoch 390/500\n",
      "222/222 [==============================] - 0s 51us/step - loss: 3.7445e-06 - val_loss: 0.0103\n",
      "Epoch 391/500\n",
      "222/222 [==============================] - 0s 57us/step - loss: 2.6392e-06 - val_loss: 0.0105\n",
      "Epoch 392/500\n",
      "222/222 [==============================] - 0s 55us/step - loss: 2.0185e-06 - val_loss: 0.0107\n",
      "Epoch 393/500\n",
      "222/222 [==============================] - 0s 55us/step - loss: 2.0117e-06 - val_loss: 0.0107\n",
      "Epoch 394/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 1.4123e-06 - val_loss: 0.0106\n",
      "Epoch 395/500\n",
      "222/222 [==============================] - 0s 57us/step - loss: 1.3032e-06 - val_loss: 0.0104\n",
      "Epoch 396/500\n",
      "222/222 [==============================] - 0s 48us/step - loss: 1.4378e-06 - val_loss: 0.0107\n",
      "Epoch 397/500\n",
      "222/222 [==============================] - 0s 52us/step - loss: 8.2944e-07 - val_loss: 0.0107\n",
      "Epoch 398/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 6.5309e-07 - val_loss: 0.0106\n",
      "Epoch 399/500\n",
      "222/222 [==============================] - 0s 59us/step - loss: 5.2545e-07 - val_loss: 0.0104\n",
      "Epoch 400/500\n",
      "222/222 [==============================] - 0s 60us/step - loss: 4.8409e-07 - val_loss: 0.0105\n",
      "Epoch 401/500\n",
      "222/222 [==============================] - 0s 60us/step - loss: 5.2178e-07 - val_loss: 0.0106\n",
      "Epoch 402/500\n",
      "222/222 [==============================] - 0s 61us/step - loss: 4.0260e-07 - val_loss: 0.0106\n",
      "Epoch 403/500\n",
      "222/222 [==============================] - 0s 52us/step - loss: 8.9025e-07 - val_loss: 0.0106\n",
      "Epoch 404/500\n",
      "222/222 [==============================] - 0s 51us/step - loss: 3.5490e-07 - val_loss: 0.0104\n",
      "Epoch 405/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 2.8689e-07 - val_loss: 0.0104\n",
      "Epoch 406/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 3.7734e-07 - val_loss: 0.0105\n",
      "Epoch 407/500\n",
      "222/222 [==============================] - 0s 55us/step - loss: 7.3088e-07 - val_loss: 0.0106\n",
      "Epoch 408/500\n",
      "222/222 [==============================] - 0s 57us/step - loss: 5.2053e-07 - val_loss: 0.0105\n",
      "Epoch 409/500\n",
      "222/222 [==============================] - 0s 64us/step - loss: 5.1609e-07 - val_loss: 0.0103\n",
      "Epoch 410/500\n",
      "222/222 [==============================] - 0s 51us/step - loss: 6.1798e-07 - val_loss: 0.0104\n",
      "Epoch 411/500\n",
      "222/222 [==============================] - 0s 59us/step - loss: 8.2778e-07 - val_loss: 0.0105\n",
      "Epoch 412/500\n",
      "222/222 [==============================] - 0s 57us/step - loss: 3.4368e-07 - val_loss: 0.0103\n",
      "Epoch 413/500\n",
      "222/222 [==============================] - 0s 53us/step - loss: 6.6361e-07 - val_loss: 0.0106\n",
      "Epoch 414/500\n",
      "222/222 [==============================] - 0s 74us/step - loss: 1.4175e-06 - val_loss: 0.0103\n",
      "Epoch 415/500\n",
      "222/222 [==============================] - 0s 61us/step - loss: 7.8572e-07 - val_loss: 0.0104\n",
      "Epoch 416/500\n",
      "222/222 [==============================] - 0s 64us/step - loss: 5.4639e-07 - val_loss: 0.0106\n",
      "Epoch 417/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 2.8045e-07 - val_loss: 0.0106\n",
      "Epoch 418/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 4.5060e-07 - val_loss: 0.0104\n",
      "Epoch 419/500\n",
      "222/222 [==============================] - 0s 51us/step - loss: 5.4008e-07 - val_loss: 0.0106\n",
      "Epoch 420/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 3.0787e-07 - val_loss: 0.0105\n",
      "Epoch 421/500\n",
      "222/222 [==============================] - 0s 51us/step - loss: 1.3973e-07 - val_loss: 0.0104\n",
      "Epoch 422/500\n",
      "222/222 [==============================] - 0s 49us/step - loss: 4.1683e-07 - val_loss: 0.0104\n",
      "Epoch 423/500\n",
      "222/222 [==============================] - 0s 61us/step - loss: 1.4281e-07 - val_loss: 0.0104\n",
      "Epoch 424/500\n",
      "222/222 [==============================] - 0s 60us/step - loss: 1.4260e-07 - val_loss: 0.0106\n",
      "Epoch 425/500\n",
      "222/222 [==============================] - 0s 62us/step - loss: 2.2386e-07 - val_loss: 0.0105\n",
      "Epoch 426/500\n",
      "222/222 [==============================] - 0s 52us/step - loss: 5.1396e-07 - val_loss: 0.0105\n",
      "Epoch 427/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 5.0207e-07 - val_loss: 0.0104\n",
      "Epoch 428/500\n",
      "222/222 [==============================] - 0s 50us/step - loss: 3.9299e-07 - val_loss: 0.0105\n",
      "Epoch 429/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 1.0036e-06 - val_loss: 0.0105\n",
      "Epoch 430/500\n",
      "222/222 [==============================] - 0s 55us/step - loss: 4.7961e-07 - val_loss: 0.0103\n",
      "Epoch 431/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 3.0317e-07 - val_loss: 0.0103\n",
      "Epoch 432/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 3.0475e-07 - val_loss: 0.0103\n",
      "Epoch 433/500\n",
      "222/222 [==============================] - 0s 50us/step - loss: 2.7923e-07 - val_loss: 0.0103\n",
      "Epoch 434/500\n",
      "222/222 [==============================] - 0s 53us/step - loss: 1.3820e-06 - val_loss: 0.0105\n",
      "Epoch 435/500\n",
      "222/222 [==============================] - 0s 47us/step - loss: 2.0702e-06 - val_loss: 0.0108\n",
      "Epoch 436/500\n",
      "222/222 [==============================] - 0s 52us/step - loss: 2.2861e-06 - val_loss: 0.0107\n",
      "Epoch 437/500\n",
      "222/222 [==============================] - 0s 55us/step - loss: 6.4258e-07 - val_loss: 0.0107\n",
      "Epoch 438/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 1.8989e-06 - val_loss: 0.0105\n",
      "Epoch 439/500\n",
      "222/222 [==============================] - 0s 59us/step - loss: 1.3611e-06 - val_loss: 0.0104\n",
      "Epoch 440/500\n",
      "222/222 [==============================] - 0s 62us/step - loss: 9.2657e-07 - val_loss: 0.0105\n",
      "Epoch 441/500\n",
      "222/222 [==============================] - 0s 59us/step - loss: 1.0495e-06 - val_loss: 0.0103\n",
      "Epoch 442/500\n",
      "222/222 [==============================] - 0s 67us/step - loss: 1.2918e-06 - val_loss: 0.0102\n",
      "Epoch 443/500\n",
      "222/222 [==============================] - 0s 65us/step - loss: 1.1351e-06 - val_loss: 0.0104\n",
      "Epoch 444/500\n",
      "222/222 [==============================] - 0s 59us/step - loss: 6.4751e-07 - val_loss: 0.0106\n",
      "Epoch 445/500\n",
      "222/222 [==============================] - 0s 60us/step - loss: 1.4834e-06 - val_loss: 0.0107\n",
      "Epoch 446/500\n",
      "222/222 [==============================] - 0s 48us/step - loss: 1.9982e-06 - val_loss: 0.0106\n",
      "Epoch 447/500\n",
      "222/222 [==============================] - 0s 51us/step - loss: 1.2326e-06 - val_loss: 0.0109\n",
      "Epoch 448/500\n",
      "222/222 [==============================] - 0s 51us/step - loss: 2.5970e-06 - val_loss: 0.0105\n",
      "Epoch 449/500\n",
      "222/222 [==============================] - 0s 60us/step - loss: 2.6739e-06 - val_loss: 0.0104\n",
      "Epoch 450/500\n",
      "222/222 [==============================] - 0s 60us/step - loss: 6.9349e-06 - val_loss: 0.0100\n",
      "Epoch 451/500\n",
      "222/222 [==============================] - 0s 60us/step - loss: 4.7864e-06 - val_loss: 0.0102\n",
      "Epoch 452/500\n",
      "222/222 [==============================] - 0s 57us/step - loss: 4.8510e-06 - val_loss: 0.0106\n",
      "Epoch 453/500\n",
      "222/222 [==============================] - 0s 51us/step - loss: 9.9065e-06 - val_loss: 0.0111\n",
      "Epoch 454/500\n",
      "222/222 [==============================] - 0s 47us/step - loss: 4.5524e-06 - val_loss: 0.0112\n",
      "Epoch 455/500\n",
      "222/222 [==============================] - 0s 49us/step - loss: 1.8595e-05 - val_loss: 0.0109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 456/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 8.6094e-06 - val_loss: 0.0108\n",
      "Epoch 457/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 4.7115e-06 - val_loss: 0.0101\n",
      "Epoch 458/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 3.1653e-06 - val_loss: 0.0101\n",
      "Epoch 459/500\n",
      "222/222 [==============================] - 0s 50us/step - loss: 1.8290e-06 - val_loss: 0.0104\n",
      "Epoch 460/500\n",
      "222/222 [==============================] - 0s 53us/step - loss: 4.8036e-06 - val_loss: 0.0108\n",
      "Epoch 461/500\n",
      "222/222 [==============================] - 0s 57us/step - loss: 1.1814e-05 - val_loss: 0.0106\n",
      "Epoch 462/500\n",
      "222/222 [==============================] - 0s 60us/step - loss: 3.6074e-05 - val_loss: 0.0105\n",
      "Epoch 463/500\n",
      "222/222 [==============================] - 0s 55us/step - loss: 6.0141e-06 - val_loss: 0.0105\n",
      "Epoch 464/500\n",
      "222/222 [==============================] - 0s 53us/step - loss: 1.0480e-05 - val_loss: 0.0099\n",
      "Epoch 465/500\n",
      "222/222 [==============================] - 0s 51us/step - loss: 4.7898e-05 - val_loss: 0.0110\n",
      "Epoch 466/500\n",
      "222/222 [==============================] - 0s 61us/step - loss: 3.7648e-05 - val_loss: 0.0099\n",
      "Epoch 467/500\n",
      "222/222 [==============================] - 0s 50us/step - loss: 3.9108e-05 - val_loss: 0.0091\n",
      "Epoch 468/500\n",
      "222/222 [==============================] - 0s 53us/step - loss: 4.8138e-05 - val_loss: 0.0093\n",
      "Epoch 469/500\n",
      "222/222 [==============================] - 0s 55us/step - loss: 6.0650e-05 - val_loss: 0.0093\n",
      "Epoch 470/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 9.8303e-05 - val_loss: 0.0115\n",
      "Epoch 471/500\n",
      "222/222 [==============================] - 0s 65us/step - loss: 2.4544e-04 - val_loss: 0.0122\n",
      "Epoch 472/500\n",
      "222/222 [==============================] - 0s 66us/step - loss: 7.6885e-05 - val_loss: 0.0107\n",
      "Epoch 473/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 1.5824e-04 - val_loss: 0.0096\n",
      "Epoch 474/500\n",
      "222/222 [==============================] - 0s 47us/step - loss: 1.5236e-04 - val_loss: 0.0082\n",
      "Epoch 475/500\n",
      "222/222 [==============================] - 0s 52us/step - loss: 2.4559e-04 - val_loss: 0.0110\n",
      "Epoch 476/500\n",
      "222/222 [==============================] - 0s 60us/step - loss: 1.1715e-04 - val_loss: 0.0094\n",
      "Epoch 477/500\n",
      "222/222 [==============================] - 0s 52us/step - loss: 4.2111e-04 - val_loss: 0.0088\n",
      "Epoch 478/500\n",
      "222/222 [==============================] - 0s 55us/step - loss: 2.7152e-04 - val_loss: 0.0109\n",
      "Epoch 479/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 1.3717e-04 - val_loss: 0.0117\n",
      "Epoch 480/500\n",
      "222/222 [==============================] - 0s 51us/step - loss: 1.5635e-04 - val_loss: 0.0119\n",
      "Epoch 481/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 1.6643e-04 - val_loss: 0.0102\n",
      "Epoch 482/500\n",
      "222/222 [==============================] - 0s 63us/step - loss: 1.5305e-04 - val_loss: 0.0147\n",
      "Epoch 483/500\n",
      "222/222 [==============================] - 0s 68us/step - loss: 2.2808e-04 - val_loss: 0.0117\n",
      "Epoch 484/500\n",
      "222/222 [==============================] - 0s 53us/step - loss: 1.7963e-04 - val_loss: 0.0105\n",
      "Epoch 485/500\n",
      "222/222 [==============================] - 0s 48us/step - loss: 1.0811e-04 - val_loss: 0.0100\n",
      "Epoch 486/500\n",
      "222/222 [==============================] - 0s 48us/step - loss: 2.1581e-04 - val_loss: 0.0105\n",
      "Epoch 487/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 2.7779e-04 - val_loss: 0.0077\n",
      "Epoch 488/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 3.6593e-04 - val_loss: 0.0093\n",
      "Epoch 489/500\n",
      "222/222 [==============================] - 0s 54us/step - loss: 1.9090e-04 - val_loss: 0.0101\n",
      "Epoch 490/500\n",
      "222/222 [==============================] - 0s 50us/step - loss: 8.6980e-05 - val_loss: 0.0101\n",
      "Epoch 491/500\n",
      "222/222 [==============================] - 0s 53us/step - loss: 8.4290e-05 - val_loss: 0.0119\n",
      "Epoch 492/500\n",
      "222/222 [==============================] - 0s 89us/step - loss: 4.2847e-05 - val_loss: 0.0128\n",
      "Epoch 493/500\n",
      "222/222 [==============================] - 0s 61us/step - loss: 5.0891e-05 - val_loss: 0.0125\n",
      "Epoch 494/500\n",
      "222/222 [==============================] - 0s 56us/step - loss: 2.4433e-05 - val_loss: 0.0113\n",
      "Epoch 495/500\n",
      "222/222 [==============================] - 0s 52us/step - loss: 2.1586e-05 - val_loss: 0.0115\n",
      "Epoch 496/500\n",
      "222/222 [==============================] - 0s 58us/step - loss: 1.3737e-05 - val_loss: 0.0113\n",
      "Epoch 497/500\n",
      "222/222 [==============================] - 0s 67us/step - loss: 1.0585e-05 - val_loss: 0.0119\n",
      "Epoch 498/500\n",
      "222/222 [==============================] - 0s 52us/step - loss: 1.0629e-05 - val_loss: 0.0123\n",
      "Epoch 499/500\n",
      "222/222 [==============================] - 0s 62us/step - loss: 1.3883e-05 - val_loss: 0.0106\n",
      "Epoch 500/500\n",
      "222/222 [==============================] - 0s 51us/step - loss: 3.0062e-05 - val_loss: 0.0118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f63923001d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.fit(X, y,epochs=500 ,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6334617358>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(y)\n",
    "plt.plot(simple_model.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310.7197816857492"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = simple_model.predict(X) * 200\n",
    "y = y * 200\n",
    "score(y_pred, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test model in the other unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = units[10]\n",
    "infer_seq_length = 9\n",
    "y_test = data.time.values[infer_seq_length:]\n",
    "y_test = max(y_test) - y_test\n",
    "scale = max(data.time.values[infer_seq_length:])\n",
    "new_data = scaler_minmax.fit_transform(data)\n",
    "# new_data = new_data.values\n",
    "# new_data = scaler_minmax.fit_transform(data)\n",
    "\n",
    "d = []\n",
    "for i in range(new_data.shape[0]-infer_seq_length):\n",
    "    d.append(new_data[i:i+infer_seq_length+1].tolist())\n",
    "d = np.array(d)\n",
    "X_test = d[:,:,2:]\n",
    "# y_test = d[:,infer_seq_length,1]\n",
    "# y_test = max(y_test) - y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6334592588>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_test)\n",
    "plt.plot(simple_model.predict(X_test)*200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1762.7260657221884"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = simple_model.predict(X_test) * 200\n",
    "y_test = y_test \n",
    "score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model in test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30430.20342261348"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = []\n",
    "for i in range(100):\n",
    "    data = test_units[i]\n",
    "    infer_seq_length = 9\n",
    "    new_data = scaler_minmax.fit_transform(data)\n",
    "    d = []\n",
    "    for i in range(new_data.shape[0]-infer_seq_length):\n",
    "        d.append(new_data[i:i+infer_seq_length+1].tolist())\n",
    "    d = np.array(d)\n",
    "    # X = d[:,:,2:]\n",
    "    X_test = d[:,:,2:]\n",
    "    preds.append((simple_model.predict(X_test)*200)[-1])\n",
    "score(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123472.17637864401"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline1 = [50] * 100\n",
    "score(labels, baseline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
